{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 1: Predicting Left-Handedness from Psychological Factors\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "We'll walk through a full data science problem in this lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Define The Problem.\n",
    "\n",
    "You're currently a data scientist working at a university. A professor of psychology is attempting to study the relationship between personalities and left-handedness. They have tasked you with gathering evidence so that they may publish.\n",
    "\n",
    "Specifically, the professor says \"I need to prove that left-handedness is caused by some personality trait. Go find that personality trait and the data to back it up.\"\n",
    "\n",
    "As a data scientist, you know that any real data science problem must be **specific** and **conclusively answerable**. For example:\n",
    "- Bad data science problem: \"What is the link between obesity and blood pressure?\"\n",
    "    - This is vague and is not conclusively answerable. That is, two people might look at the conclusion and one may say \"Sure, the problem has been answered!\" and the other may say \"The problem has not yet been answered.\"\n",
    "- Good data science problem: \"Does an association exist between obesity and blood pressure?\"\n",
    "    - This is more specific and is conclusively answerable. The problem specifically is asking for a \"Yes\" or \"No\" answer. Based on that, two independent people should both be able to say either \"Yes, the problem has been answered\" or \"No, the problem has not yet been answered.\"\n",
    "- Excellent data science problem: \"As obesity increases, how does blood pressure change?\"\n",
    "    - This is very specific and is conclusively answerable. The problem specifically seeks to understand the effect of one variable on the other.\n",
    "\n",
    "### 1. In the context of the left-handedness and personality example, what are three specific and conclusively answerable problems that you could answer using data science? \n",
    "\n",
    "> You might find it helpful to check out the codebook in the repo for some inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:  \n",
    "How does probability of left-handedness changes with inclination to decorate things?  \n",
    "How does probability of left-handedness changes with ability to remember birthdays?  \n",
    "How does probability of left-handedness changes with tendency to give people handmade gifts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 2. Read in the file titled \"data.csv.\"\n",
    "> Hint: Despite being saved as a .csv file, you won't be able to simply `pd.read_csv()` this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "pd.set_option(\"display.max_rows\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data.csv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Suppose that, instead of us giving you this data in a file, you were actually conducting a survey to gather this data yourself. From an ethics/privacy point of view, what are three things you might consider when attempting to gather this data?\n",
    "> When working with sensitive data like sexual orientation or gender identity, we need to consider how this data could be used if it fell into the wrong hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:  \n",
    "Anonymize any personal data identifier, name, ID number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 4. Conduct exploratory data analysis on this dataset.\n",
    "> If you haven't already, be sure to check out the codebook in the repo, as that will help in your EDA process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace \"both-handedness\" as \"left-handedness\"\n",
    "df['hand']=df['hand'].replace(3,2)\n",
    "#drop hand==0\n",
    "df=df[~(df['hand']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "pd.set_option(\"display.max_rows\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode a few fields\n",
    "ohe_list=['engnat','education','gender','orientation','race','religion','fromgoogle','country']\n",
    "df=pd.get_dummies(df,prefix=ohe_list,columns=ohe_list,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender_2        -0.058587\n",
       "engnat_2        -0.052819\n",
       "orientation_1   -0.048535\n",
       "country_AU      -0.038409\n",
       "Q8              -0.034042\n",
       "Q23             -0.033173\n",
       "Q20             -0.032990\n",
       "Q22             -0.032774\n",
       "race_7          -0.030348\n",
       "religion_5      -0.028037\n",
       "country_HK      -0.027781\n",
       "country_BR      -0.027781\n",
       "country_IN      -0.027379\n",
       "race_2          -0.027283\n",
       "country_FI      -0.027092\n",
       "Q18             -0.026840\n",
       "Q6              -0.026208\n",
       "country_PL      -0.022624\n",
       "Q14             -0.021733\n",
       "country_CL      -0.021699\n",
       "Q40             -0.021517\n",
       "country_DE      -0.021365\n",
       "Q2              -0.021204\n",
       "Q10             -0.020887\n",
       "Q24             -0.020780\n",
       "country_MX      -0.020687\n",
       "country_JO      -0.020687\n",
       "religion_3      -0.019984\n",
       "introelapse     -0.019016\n",
       "testelapse      -0.018841\n",
       "country_RO      -0.018498\n",
       "country_EE      -0.018498\n",
       "country_AT      -0.017574\n",
       "country_KR      -0.017301\n",
       "country_RU      -0.017301\n",
       "country_ID      -0.016493\n",
       "country_AR      -0.016016\n",
       "country_MY      -0.016016\n",
       "country_NL      -0.015932\n",
       "Q30             -0.014877\n",
       "country_PK      -0.014619\n",
       "country_LT      -0.014619\n",
       "country_CN      -0.014619\n",
       "country_EG      -0.014174\n",
       "Q36             -0.013445\n",
       "country_IT      -0.013145\n",
       "country_BG      -0.013074\n",
       "country_JP      -0.013074\n",
       "education_3     -0.011842\n",
       "country_PR      -0.011321\n",
       "country_NI      -0.011321\n",
       "country_LV      -0.011321\n",
       "country_RS      -0.011321\n",
       "country_IL      -0.011321\n",
       "country_TW      -0.011321\n",
       "country_FR      -0.011153\n",
       "country_ES      -0.011111\n",
       "Q12             -0.010641\n",
       "Q41             -0.010196\n",
       "country_SG      -0.010114\n",
       "Q32             -0.010018\n",
       "Q42             -0.009403\n",
       "country_SI      -0.009242\n",
       "country_DO      -0.009242\n",
       "fromgoogle_2    -0.007662\n",
       "country_AE      -0.007006\n",
       "country_BN      -0.006535\n",
       "country_KE      -0.006535\n",
       "country_BB      -0.006535\n",
       "country_UZ      -0.006535\n",
       "country_KH      -0.006535\n",
       "country_NP      -0.006535\n",
       "country_VN      -0.006535\n",
       "country_SK      -0.006535\n",
       "country_PF      -0.006535\n",
       "country_EC      -0.006535\n",
       "country_GE      -0.006535\n",
       "country_ZM      -0.006535\n",
       "country_DZ      -0.006535\n",
       "country_LY      -0.006535\n",
       "country_QA      -0.006535\n",
       "country_UY      -0.006535\n",
       "country_SA      -0.006535\n",
       "country_MP      -0.006535\n",
       "country_FJ      -0.006535\n",
       "country_A2      -0.006535\n",
       "country_LK      -0.006535\n",
       "country_VI      -0.006535\n",
       "country_IS      -0.006535\n",
       "country_CY      -0.006535\n",
       "race_6          -0.006497\n",
       "education_2     -0.005731\n",
       "Q34             -0.003711\n",
       "religion_2      -0.001727\n",
       "religion_1      -0.000870\n",
       "Q16             -0.000424\n",
       "Q15              0.000514\n",
       "Q19              0.001304\n",
       "country_TZ       0.001637\n",
       "country_PT       0.001637\n",
       "country_CZ       0.001637\n",
       "religion_7       0.002636\n",
       "Q39              0.002737\n",
       "country_IE       0.002840\n",
       "Q28              0.003164\n",
       "Q21              0.003180\n",
       "country_TH       0.004717\n",
       "country_EU       0.004717\n",
       "country_NO       0.004718\n",
       "Q43              0.005264\n",
       "Q37              0.006152\n",
       "country_NZ       0.006391\n",
       "country_TR       0.006675\n",
       "country_GR       0.006675\n",
       "Q44              0.007356\n",
       "orientation_2    0.007533\n",
       "race_4           0.007628\n",
       "Q9               0.008059\n",
       "Q4               0.008252\n",
       "country_PE       0.008542\n",
       "country_HU       0.008542\n",
       "religion_4       0.008984\n",
       "country_BE       0.009215\n",
       "Q11              0.010738\n",
       "education_4      0.011227\n",
       "country_ZA       0.012414\n",
       "Q13              0.012476\n",
       "race_3           0.012790\n",
       "country_CA       0.013586\n",
       "country_DK       0.015390\n",
       "country_CO       0.015390\n",
       "Q27              0.016619\n",
       "education_1      0.016740\n",
       "Q31              0.019036\n",
       "age              0.019036\n",
       "country_GB       0.019108\n",
       "country_SE       0.019241\n",
       "race_5           0.019290\n",
       "Q38              0.019543\n",
       "religion_6       0.019824\n",
       "orientation_4    0.020702\n",
       "country_LB       0.021319\n",
       "country_ZW       0.021319\n",
       "country_VE       0.021319\n",
       "Q33              0.023142\n",
       "orientation_3    0.025465\n",
       "Q26              0.026839\n",
       "Q7               0.026990\n",
       "Q29              0.027802\n",
       "gender_1         0.028445\n",
       "Q5               0.032589\n",
       "country_PH       0.033441\n",
       "country_CH       0.034036\n",
       "Q25              0.034370\n",
       "Q3               0.035326\n",
       "gender_3         0.036116\n",
       "country_KW       0.036681\n",
       "country_TN       0.036681\n",
       "country_JM       0.036681\n",
       "orientation_5    0.036793\n",
       "country_HR       0.036943\n",
       "Q1               0.037260\n",
       "country_US       0.037902\n",
       "Q17              0.039154\n",
       "race_1           0.047119\n",
       "engnat_1         0.048973\n",
       "country_IM       0.051881\n",
       "country_UA       0.051881\n",
       "Q35              0.065766\n",
       "hand             1.000000\n",
       "Name: hand, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['hand'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most correlating feature is merely a little more than 5% correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 5. Suppose I wanted to use Q1 - Q44 to predict whether or not the person is left-handed. Would this be a classification or regression problem? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Classification. The final predictor label is a boolean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed based on their responses to Q1 - Q44. Before doing that, however, you remember that it is often a good idea to standardize your variables. In general, why would we standardize our variables? Give an example of when we would standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:  \n",
    "Standardization allows easier treatement for features with different ranges.  \n",
    "Usually you'd standardised a feature that is known to have Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Give an example of when we might not standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: When your data is not numerical, or of unknown distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Based on your answers to 6 and 7, do you think we should standardize our predictor variables in this case? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Probably no need, since the responses across the questions are of a fixed range 1 to 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed. What munging/cleaning do we need to do to our $y$ variable in order to explicitly answer this question? Do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Features should have no nulls, and all should be numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find columnes with null. Should show up empty.\n",
    "df.columns[df.isnull().sum()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1               int64\n",
       "Q2               int64\n",
       "Q3               int64\n",
       "Q4               int64\n",
       "Q5               int64\n",
       "Q6               int64\n",
       "Q7               int64\n",
       "Q8               int64\n",
       "Q9               int64\n",
       "Q10              int64\n",
       "Q11              int64\n",
       "Q12              int64\n",
       "Q13              int64\n",
       "Q14              int64\n",
       "Q15              int64\n",
       "Q16              int64\n",
       "Q17              int64\n",
       "Q18              int64\n",
       "Q19              int64\n",
       "Q20              int64\n",
       "Q21              int64\n",
       "Q22              int64\n",
       "Q23              int64\n",
       "Q24              int64\n",
       "Q25              int64\n",
       "Q26              int64\n",
       "Q27              int64\n",
       "Q28              int64\n",
       "Q29              int64\n",
       "Q30              int64\n",
       "Q31              int64\n",
       "Q32              int64\n",
       "Q33              int64\n",
       "Q34              int64\n",
       "Q35              int64\n",
       "Q36              int64\n",
       "Q37              int64\n",
       "Q38              int64\n",
       "Q39              int64\n",
       "Q40              int64\n",
       "Q41              int64\n",
       "Q42              int64\n",
       "Q43              int64\n",
       "Q44              int64\n",
       "introelapse      int64\n",
       "testelapse       int64\n",
       "age              int64\n",
       "hand             int64\n",
       "engnat_1         uint8\n",
       "engnat_2         uint8\n",
       "education_1      uint8\n",
       "education_2      uint8\n",
       "education_3      uint8\n",
       "education_4      uint8\n",
       "gender_1         uint8\n",
       "gender_2         uint8\n",
       "gender_3         uint8\n",
       "orientation_1    uint8\n",
       "orientation_2    uint8\n",
       "orientation_3    uint8\n",
       "orientation_4    uint8\n",
       "orientation_5    uint8\n",
       "race_1           uint8\n",
       "race_2           uint8\n",
       "race_3           uint8\n",
       "race_4           uint8\n",
       "race_5           uint8\n",
       "race_6           uint8\n",
       "race_7           uint8\n",
       "religion_1       uint8\n",
       "religion_2       uint8\n",
       "religion_3       uint8\n",
       "religion_4       uint8\n",
       "religion_5       uint8\n",
       "religion_6       uint8\n",
       "religion_7       uint8\n",
       "fromgoogle_2     uint8\n",
       "country_A2       uint8\n",
       "country_AE       uint8\n",
       "country_AR       uint8\n",
       "country_AT       uint8\n",
       "country_AU       uint8\n",
       "country_BB       uint8\n",
       "country_BE       uint8\n",
       "country_BG       uint8\n",
       "country_BN       uint8\n",
       "country_BR       uint8\n",
       "country_CA       uint8\n",
       "country_CH       uint8\n",
       "country_CL       uint8\n",
       "country_CN       uint8\n",
       "country_CO       uint8\n",
       "country_CY       uint8\n",
       "country_CZ       uint8\n",
       "country_DE       uint8\n",
       "country_DK       uint8\n",
       "country_DO       uint8\n",
       "country_DZ       uint8\n",
       "country_EC       uint8\n",
       "country_EE       uint8\n",
       "country_EG       uint8\n",
       "country_ES       uint8\n",
       "country_EU       uint8\n",
       "country_FI       uint8\n",
       "country_FJ       uint8\n",
       "country_FR       uint8\n",
       "country_GB       uint8\n",
       "country_GE       uint8\n",
       "country_GR       uint8\n",
       "country_HK       uint8\n",
       "country_HR       uint8\n",
       "country_HU       uint8\n",
       "country_ID       uint8\n",
       "country_IE       uint8\n",
       "country_IL       uint8\n",
       "country_IM       uint8\n",
       "country_IN       uint8\n",
       "country_IS       uint8\n",
       "country_IT       uint8\n",
       "country_JM       uint8\n",
       "country_JO       uint8\n",
       "country_JP       uint8\n",
       "country_KE       uint8\n",
       "country_KH       uint8\n",
       "country_KR       uint8\n",
       "country_KW       uint8\n",
       "country_LB       uint8\n",
       "country_LK       uint8\n",
       "country_LT       uint8\n",
       "country_LV       uint8\n",
       "country_LY       uint8\n",
       "country_MP       uint8\n",
       "country_MX       uint8\n",
       "country_MY       uint8\n",
       "country_NI       uint8\n",
       "country_NL       uint8\n",
       "country_NO       uint8\n",
       "country_NP       uint8\n",
       "country_NZ       uint8\n",
       "country_PE       uint8\n",
       "country_PF       uint8\n",
       "country_PH       uint8\n",
       "country_PK       uint8\n",
       "country_PL       uint8\n",
       "country_PR       uint8\n",
       "country_PT       uint8\n",
       "country_QA       uint8\n",
       "country_RO       uint8\n",
       "country_RS       uint8\n",
       "country_RU       uint8\n",
       "country_SA       uint8\n",
       "country_SE       uint8\n",
       "country_SG       uint8\n",
       "country_SI       uint8\n",
       "country_SK       uint8\n",
       "country_TH       uint8\n",
       "country_TN       uint8\n",
       "country_TR       uint8\n",
       "country_TW       uint8\n",
       "country_TZ       uint8\n",
       "country_UA       uint8\n",
       "country_US       uint8\n",
       "country_UY       uint8\n",
       "country_UZ       uint8\n",
       "country_VE       uint8\n",
       "country_VI       uint8\n",
       "country_VN       uint8\n",
       "country_ZA       uint8\n",
       "country_ZM       uint8\n",
       "country_ZW       uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for non-int\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. The professor for whom you work suggests that you set $k = 4$. In this specific case, why might this be a bad idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Only consindering the nearest 4 neighbours is rather myopic. The model should look at more neighbours to generalize better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Let's *(finally)* use $k$-nearest neighbors to predict whether or not a person is left-handed!\n",
    "\n",
    "> Be sure to create a train/test split with your data!\n",
    "\n",
    "> Create four separate models, one with $k = 3$, one with $k = 5$, one with $k = 15$, and one with $k = 25$.\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up X and y\n",
    "X=df.iloc[:,0:44]\n",
    "y=df['hand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3542\n",
       "2     631\n",
       "Name: hand, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct a train/test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors=[3,5,15,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset before every run\n",
    "knn_models=[]\n",
    "\n",
    "for i in range(len(n_neighbors)):\n",
    "    knn=KNeighborsClassifier(n_neighbors=n_neighbors[i])\n",
    "    knn.fit(X_train,y_train)\n",
    "    knn_models.append(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being good data scientists, we know that we might not run just one type of model. We might run many different models and see which is best.\n",
    "\n",
    "### 12. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, let's check the [documentation for logistic regression in sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Is there default regularization? If so, what is it? If not, how do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Yes, it is applied by default. L1 and L2 regularization are both supported. Elastic Net is only supported by `saga` solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, should we standardize our features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Standardization is not required for logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Let's use logistic regression to predict whether or not the person is left-handed.\n",
    "\n",
    "\n",
    "> Be sure to use the same train/test split with your data as with your $k$-NN model above!\n",
    "\n",
    "> Create four separate models, one with LASSO and $\\alpha = 1$, one with LASSO and $\\alpha = 10$, one with Ridge and $\\alpha = 1$, and one with Ridge and $\\alpha = 10$. *(Hint: Be careful with how you specify $\\alpha$ in your model!)*\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties=['l1','l2']\n",
    "alphas=[1,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.007448857943865028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.011336064057686036"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.006749894507787276"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, solver='liblinear')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.00943170403922317"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reset before every run\n",
    "logreg_models=[]\n",
    "\n",
    "for p in penalties:\n",
    "    for a in alphas:\n",
    "        logreg=LogisticRegression(penalty=p,C=1/a,solver='liblinear')\n",
    "        logreg.fit(X_train,y_train)\n",
    "        display(logreg)\n",
    "        display(logreg.coef_.mean())\n",
    "        logreg_models.append(logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Evaluate the model(s).\n",
    "\n",
    "### 15. Before calculating any score on your data, take a step back. Think about your $X$ variable and your $Y$ variable. Do you think your $X$ variables will do a good job of predicting your $Y$ variable? Why or why not? What impact do you think this will have on your scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Unable to tell. Correlation feels low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Using accuracy as your metric, evaluate all eight of your models on both the training and testing sets. Put your scores below. (If you want to be fancy and generate a table in Markdown, there's a [Markdown table generator site linked here](https://www.tablesgenerator.com/markdown_tables#).)\n",
    "- Note: Your answers here might look a little weird. You didn't do anything wrong; that's to be expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8705656759348035"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8497922658996484"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8494726749760306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.849153084052413"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.849153084052413"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8494726749760306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.849153084052413"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8494726749760306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in [*knn_models, *logreg_models]:\n",
    "    display(model.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8007662835249042"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8247126436781609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8477011494252874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8477011494252874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8477011494252874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8467432950191571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8477011494252874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8477011494252874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in [*knn_models, *logreg_models]:\n",
    "    display(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: It does seems that all the logistic regression models perform equally well. Knn classifier with $k\\ge15$ plateaus in accuracy and is marginally better than the logistic regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. In which of your $k$-NN models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: First 2 models. $k=3$ and $k=5$. Training accuracy is higher than test accuracy by quite a bit, and since there is room for improvement with bigger $k$, we can deduce that these 2 were overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Broadly speaking, how does the value of $k$ in $k$-NN affect the bias-variance tradeoff? (i.e. As $k$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: as K increases, bias increases but variance decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. If you have a $k$-NN model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: increase k, reduce number of features, increase number or rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. In which of your logistic regression models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: All of them. The accuracy for training set is higher than test set, suggesting high bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Broadly speaking, how does the value of $C$ in logistic regression affect the bias-variance tradeoff? (i.e. As $C$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: as C increases, there is weaker regularization. Overfitting increase, i.e. bias decrease, variance increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. For your logistic regression models, play around with the regularization hyperparameter, $C$. As you vary $C$, what happens to the fit and coefficients in the model? What do you think this means in the context of this specific problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: As C decreases, coefficients become more negative. Bias increase. This means the model has a stronger regularisation strength and can generalize better.  \n",
    "This also mean that the model will predict left-handedness with less sensitivity to the scores of Q1 to Q44."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. If you have a logistic regression model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: add more rows, reduce features, increase regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "### 24. Suppose you want to understand which psychological features are most important in determining left-handedness. Would you rather use $k$-NN or logistic regression? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: LogReg  \n",
    "\n",
    "LogReg gives coefficients which can be analyzed to study the 44 questions, on which one influence the probaility the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Select your logistic regression model that utilized LASSO regularization with $\\alpha = 1$. Interpret the coefficient for `Q1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 44)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef=logreg_models[0].coef_\n",
    "display(coef.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The 44 values are the amount of change to the probability for every unit increase in the question answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. If you have to select one model overall to be your *best* model, which model would you select? Why?\n",
    "- Usually in the \"real world,\" you'll fit many types of models but ultimately need to pick only one! (For example, a client may not understand what it means to have multiple models, or if you're using an algorithm to make a decision, it's probably pretty challenging to use two or more algorithms simultaneously.) It's not always an easy choice, but you'll have to make it soon enough. Pick a model and defend why you picked this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: For prediction purpose, I'd pick KNN with $k=25$.  \n",
    "KNN is a simple 'voting machine' comparing nearest neighbours, whereas LogReg requires linear independence across the 44 questions. It is mathematically more complex too.  \n",
    "\n",
    "LogReg however is more useful if we want to dissect the changes using a coefficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Circle back to the three specific and conclusively answerable questions you came up with in Q1. Answer one of these for the professor based on the model you selected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12688402220784448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.019577084291597834"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.10459280932507098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.08413500425777144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(max(coef[0,:]))\n",
    "display(coef[0,3])\n",
    "display(coef[0,20])\n",
    "display(coef[0,43])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:It does appear that Q21: <b>I do not remember birthdays</b> contributes to the probability negatively by 10% with each increase in the score.  \n",
    "This means that respondants who tend not to remmber birthdays, are likely <b>not</b> to be left-handed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "Looking for more to do? Probably not - you're busy! But if you want to, consider exploring the following. (They could make for a blog post!)\n",
    "- Create a visual plot comparing training and test metrics for various values of $k$ and various regularization schemes in logistic regression.\n",
    "- Rather than just evaluating models based on accuracy, consider using sensitivity, specificity, etc.\n",
    "- In the context of predicting left-handedness, why are unbalanced classes concerning? If you were to re-do this process given those concerns, what changes might you make?\n",
    "- Fit and evaluate a generalized linear model other than logistic regression (e.g. Poisson regression).\n",
    "- Suppose this data were in a `SQL` database named `data` and a table named `inventory`. What `SQL` query would return the count of people who were right-handed, left-handed, both, or missing with their class labels of 1, 2, 3, and 0, respectively? (You can assume you've already logged into the database.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
